{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_validate, StratifiedShuffleSplit\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('output/data_cleaned_balanced.csv')\n",
    "\n",
    "# split data into features and target\n",
    "X = df.drop(columns=['seo class'])\n",
    "y = df['seo class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of evaluation metrics\n",
    "metrics = {'accuracy': 'accuracy',\n",
    "           'precision': 'precision_macro', \n",
    "           'recall': 'recall_macro',\n",
    "           'f1': 'f1_macro'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create stratified split for cross validation\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=.66, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of classifiers to compare\n",
    "classifiers = {'AdaBoost': AdaBoostClassifier(),\n",
    "               'BernoulliNB': BernoulliNB(),\n",
    "               'DecisionTree': DecisionTreeClassifier(),\n",
    "               'ExtraTrees': ExtraTreesClassifier(),\n",
    "               'GaussianNB': GaussianNB(),\n",
    "               'GradientBoosting': GradientBoostingClassifier(),\n",
    "               'KNeighbors': KNeighborsClassifier(),\n",
    "               'LinearSVC': LinearSVC(),\n",
    "               'RadiusNeighbors': RadiusNeighborsClassifier(),\n",
    "               'RandomForest': RandomForestClassifier(),\n",
    "               'SGD': SGDClassifier(),\n",
    "               'SVC': SVC()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_iter': 100,\n",
    "          'max_depth' : 10,\n",
    "          'penalty': 'l2',\n",
    "          'n_neighbors': 4,\n",
    "          'outlier_label': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_counts = [6, 25, 29, 42, 49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current classifier: KNeighbors 6\n"
     ]
    }
   ],
   "source": [
    "cv_results = {}\n",
    "\n",
    "for i in feature_counts:\n",
    "    for name, clf in classifiers.items():\n",
    "        # display current classifier\n",
    "        # to show progress while code is running\n",
    "        clear_output()\n",
    "        print('Current classifier: %s %d' % (name, i))\n",
    "\n",
    "        # get parameter options for current classifier\n",
    "        clf_params = clf.get_params()\n",
    "\n",
    "        # select matching parameters for current classifier from params\n",
    "        c_params = {}\n",
    "        for p in params.keys():\n",
    "            if p in clf_params.keys():\n",
    "                c_params[p] = params[p]\n",
    "\n",
    "        # set parameters\n",
    "        if c_params:\n",
    "            clf.set_params(**c_params)\n",
    "            \n",
    "        # select features\n",
    "        selector = SelectKBest(f_classif, k=i)\n",
    "        X2 = selector.fit_transform(X, y)\n",
    "\n",
    "        # cross validate classifier\n",
    "        cv = cross_validate(clf, X2, y, scoring=metrics, cv=sss)\n",
    "        \n",
    "        # save results of cross validation\n",
    "        name_i = name + '_' + str(i)\n",
    "        cv_results[name_i] = cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for name, results in cv_results.items():\n",
    "    row = name.split('_')\n",
    "    for k, v in results.items():\n",
    "        # add mean and standard deviation to data\n",
    "        row.append(v.mean())\n",
    "        row.append(v.std())\n",
    "    data.append(row)\n",
    "\n",
    "# column names for dataframe\n",
    "columns = ['classifier', 'feature count']\n",
    "for k in cv.keys():\n",
    "    k = k.replace('test_', '')\n",
    "    columns.append(k+'_mean')\n",
    "    columns.append(k+'_std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(data, columns=columns)\n",
    "results.to_csv('output/benchmarking_results_3-1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted by f1 mean\n",
    "results.sort_values(by=['f1_mean'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get standard dev columns to remove from df display\n",
    "std_c = [c for c in results.columns if '_std' in c]\n",
    "\n",
    "# set filters to narrow down results\n",
    "# Filters: F1 > 75% and Accuracy > 95%\n",
    "filter_ = (results['f1_mean'] > 0.75) & (results['accuracy_mean'] > 0.95)\n",
    "\n",
    "# filter results by f1 > 75% and accuracy > 95%, sort by fit time\n",
    "results[filter_].sort_values(by=['fit_time_mean']).drop(columns=std_c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
