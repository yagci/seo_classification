{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02_data_optimization\n",
    "\n",
    "This notebook uses the Gaussian Naive Bayes Classifier to optimize the data set. These steps are preprocessing methods, that make the data more uniform and help boost the performance of the algorithms. As before, the results are cross validated by separating the data into 5 stratified shuffle splits and measuring the mean and standard deviation of the results.\n",
    "\n",
    "The most common techniques to handle missing data are compared. These are encoding the missing values with a placeholder (in this case -1), imputing the missing value by the mean of the feature or removing the sample in which a value for one feature is missing. Removing samples with missing data has the biggest positive impact on the data, increasing the accuracy from 96% to 99% and the f1 from 75% to 80%.\n",
    "\n",
    "The dataset is highly imbalanced, with a class distribution of roughly 48, 48, 1 and 1% per class. As such, methods to over or under sample these classes are tested. A combination of both SMOTE and Tomek, in which the higher classes are under sampled and the lower classes are over sampled, boosts f1 from 75% to 97% while the accuracy score also increases from 96% to 99%.\n",
    "\n",
    "Machine Learning algorithms generally perform better when the values are on an even scale. As such, different methods of scaling the data are compared. Since most of the features in the data set are either binary (0 or 1) or have very low variance (except for speed), the algorithm performs best when no scaler is applied.\n",
    "\n",
    "When testing the scaling methods on the balanced dataset, the StandardScaler increases the performance the most. The balanced and scaled model has an accuracy of 99% and f1 of 99%. The \"balanced\", and the \"balanced and scaled\" datasets are saved to <code>output/data_balanced.csv</code> and <code>output/data_balanced_scaled.csv</code> respectively. The latter is used in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_validate, StratifiedShuffleSplit\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv('output/data_cleaned.csv')\n",
    "\n",
    "# split data into features and target\n",
    "X = df.drop(columns=['seo class'])\n",
    "y = df['seo class']\n",
    "\n",
    "# dictionary of evaluation metrics\n",
    "metrics = {'accuracy': 'accuracy',\n",
    "           'precision': 'precision_macro', \n",
    "           'recall': 'recall_macro',\n",
    "           'f1': 'f1_macro'}\n",
    "\n",
    "# create stratified split for cross validation\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=.66, random_state=22)\n",
    "\n",
    "# define classifier\n",
    "clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02-1_error_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>fit_time_mean</th>\n",
       "      <th>fit_time_std</th>\n",
       "      <th>score_time_mean</th>\n",
       "      <th>score_time_std</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>errors removed</td>\n",
       "      <td>0.352058</td>\n",
       "      <td>0.010248</td>\n",
       "      <td>0.626672</td>\n",
       "      <td>0.015262</td>\n",
       "      <td>0.990434</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.780505</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.975232</td>\n",
       "      <td>0.006765</td>\n",
       "      <td>0.804394</td>\n",
       "      <td>0.000596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>errors encoded</td>\n",
       "      <td>0.449729</td>\n",
       "      <td>0.024788</td>\n",
       "      <td>0.773060</td>\n",
       "      <td>0.039809</td>\n",
       "      <td>0.963281</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>0.757487</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.970410</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>0.758505</td>\n",
       "      <td>0.001312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>errors imputed</td>\n",
       "      <td>0.525328</td>\n",
       "      <td>0.036665</td>\n",
       "      <td>0.687711</td>\n",
       "      <td>0.013056</td>\n",
       "      <td>0.886550</td>\n",
       "      <td>0.011275</td>\n",
       "      <td>0.749924</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.931416</td>\n",
       "      <td>0.005783</td>\n",
       "      <td>0.718006</td>\n",
       "      <td>0.004957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           method  fit_time_mean  fit_time_std  score_time_mean  \\\n",
       "1  errors removed       0.352058      0.010248         0.626672   \n",
       "0  errors encoded       0.449729      0.024788         0.773060   \n",
       "2  errors imputed       0.525328      0.036665         0.687711   \n",
       "\n",
       "   score_time_std  accuracy_mean  accuracy_std  precision_mean  precision_std  \\\n",
       "1        0.015262       0.990434      0.000585        0.780505       0.000450   \n",
       "0        0.039809       0.963281      0.001391        0.757487       0.000663   \n",
       "2        0.013056       0.886550      0.011275        0.749924       0.000614   \n",
       "\n",
       "   recall_mean  recall_std   f1_mean    f1_std  \n",
       "1     0.975232    0.006765  0.804394  0.000596  \n",
       "0     0.970410    0.001742  0.758505  0.001312  \n",
       "2     0.931416    0.005783  0.718006  0.004957  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty dictionary to store results\n",
    "cv_results = {}\n",
    "\n",
    "# get datasets to compare\n",
    "# errors removed\n",
    "df_clean = df[~df.lt(0).any(1)]\n",
    "X_clean = df_clean.drop(columns=['seo class'])\n",
    "y_clean = df_clean['seo class']\n",
    "\n",
    "# errors imputed\n",
    "df_impute = df.copy(deep=True)\n",
    "df_impute[df_impute < 0] = np.nan\n",
    "X_impute = df_impute.drop(columns=['seo class'])\n",
    "y_impute = df_impute['seo class']\n",
    "\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X_impute = imp_mean.fit_transform(X_impute, y_impute)\n",
    "\n",
    "# store data in dict\n",
    "data = {'errors encoded': [X, y],\n",
    "        'errors removed': [X_clean, y_clean],\n",
    "        'errors imputed': [X_impute, y_impute]}\n",
    "\n",
    "for method, d in data.items():\n",
    "    cv = cross_validate(clf, d[0], d[1], scoring=metrics, cv=sss)\n",
    "    cv_results[method] = cv\n",
    "    \n",
    "# format data for dataframe\n",
    "data = []\n",
    "for name, results in cv_results.items():\n",
    "    row = [name]\n",
    "    for k, v in results.items():\n",
    "        # add mean and standard deviation to data\n",
    "        row.append(v.mean())\n",
    "        row.append(v.std())\n",
    "    data.append(row)\n",
    "    \n",
    "# column names for dataframe\n",
    "columns = ['method']\n",
    "for k in cv.keys():\n",
    "    k = k.replace('test_', '')\n",
    "    columns.append(k+'_mean')\n",
    "    columns.append(k+'_std')\n",
    "\n",
    "# create data frame to display cv results\n",
    "results = pd.DataFrame(data, columns=columns)\n",
    "# save data frame as csv file\n",
    "results.to_csv('output/02-1_error_encoding.csv')\n",
    "results.sort_values(by=['f1_mean'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02-2_class_balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>fit_time_mean</th>\n",
       "      <th>fit_time_std</th>\n",
       "      <th>score_time_mean</th>\n",
       "      <th>score_time_std</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>0.902941</td>\n",
       "      <td>0.011864</td>\n",
       "      <td>2.056010</td>\n",
       "      <td>0.003684</td>\n",
       "      <td>0.977984</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.978086</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.977641</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.977668</td>\n",
       "      <td>0.001215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>0.987261</td>\n",
       "      <td>0.047807</td>\n",
       "      <td>2.353501</td>\n",
       "      <td>0.147402</td>\n",
       "      <td>0.970725</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.971059</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.970725</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.000405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>0.003405</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.006630</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.963804</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>0.963946</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>0.963819</td>\n",
       "      <td>0.002159</td>\n",
       "      <td>0.963506</td>\n",
       "      <td>0.002213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Sampling</td>\n",
       "      <td>0.401700</td>\n",
       "      <td>0.019843</td>\n",
       "      <td>0.697778</td>\n",
       "      <td>0.012314</td>\n",
       "      <td>0.963281</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>0.757487</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.970410</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>0.758505</td>\n",
       "      <td>0.001312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               method  fit_time_mean  fit_time_std  score_time_mean  \\\n",
       "3          SMOTETomek       0.902941      0.011864         2.056010   \n",
       "1   RandomOverSampler       0.987261      0.047807         2.353501   \n",
       "2  RandomUnderSampler       0.003405      0.000193         0.006630   \n",
       "0         No Sampling       0.401700      0.019843         0.697778   \n",
       "\n",
       "   score_time_std  accuracy_mean  accuracy_std  precision_mean  precision_std  \\\n",
       "3        0.003684       0.977984      0.001153        0.978086       0.001137   \n",
       "1        0.147402       0.970725      0.000390        0.971059       0.000392   \n",
       "2        0.000279       0.963804      0.002169        0.963946       0.002221   \n",
       "0        0.012314       0.963281      0.001391        0.757487       0.000663   \n",
       "\n",
       "   recall_mean  recall_std   f1_mean    f1_std  \n",
       "3     0.977641    0.001193  0.977668  0.001215  \n",
       "1     0.970725    0.000390  0.970588  0.000405  \n",
       "2     0.963819    0.002159  0.963506  0.002213  \n",
       "0     0.970410    0.001742  0.758505  0.001312  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty dictionary to store results\n",
    "cv_results = {}\n",
    "\n",
    "# get scalers to compare\n",
    "\n",
    "sampler = {'No Sampling': 0,\n",
    "           'RandomOverSampler': RandomOverSampler(random_state=2),\n",
    "           'RandomUnderSampler': RandomUnderSampler(random_state=2),\n",
    "           'SMOTETomek': SMOTETomek(random_state=2)}\n",
    "\n",
    "for method, s in sampler.items():\n",
    "    # reset X and y\n",
    "    X = df.drop(columns=['seo class'])\n",
    "    y = df['seo class']\n",
    "    \n",
    "    # applies sampler to X and y\n",
    "    if type(s) != int:\n",
    "        X, y = s.fit_resample(X, y)\n",
    "    \n",
    "    cv = cross_validate(clf, X, y, scoring=metrics, cv=sss)\n",
    "    cv_results[method] = cv\n",
    "    \n",
    "# format data for dataframe\n",
    "data = []\n",
    "for name, results in cv_results.items():\n",
    "    row = [name]\n",
    "    for k, v in results.items():\n",
    "        # add mean and standard deviation to data\n",
    "        row.append(v.mean())\n",
    "        row.append(v.std())\n",
    "    data.append(row)\n",
    "    \n",
    "# column names for dataframe\n",
    "columns = ['method']\n",
    "for k in cv.keys():\n",
    "    k = k.replace('test_', '')\n",
    "    columns.append(k+'_mean')\n",
    "    columns.append(k+'_std')\n",
    "\n",
    "# create data frame to display cv results\n",
    "results = pd.DataFrame(data, columns=columns)\n",
    "# save data frame as csv file\n",
    "results.to_csv('output/02-2_class_balancing.csv')\n",
    "results.sort_values(by=['f1_mean'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02-3_data_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>fit_time_mean</th>\n",
       "      <th>fit_time_std</th>\n",
       "      <th>score_time_mean</th>\n",
       "      <th>score_time_std</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Scaling</td>\n",
       "      <td>0.411623</td>\n",
       "      <td>0.015341</td>\n",
       "      <td>0.714665</td>\n",
       "      <td>0.011657</td>\n",
       "      <td>0.963281</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>0.757487</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.970410</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>0.758505</td>\n",
       "      <td>0.001312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.523627</td>\n",
       "      <td>0.008802</td>\n",
       "      <td>0.705701</td>\n",
       "      <td>0.023381</td>\n",
       "      <td>0.939960</td>\n",
       "      <td>0.005883</td>\n",
       "      <td>0.754739</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.959500</td>\n",
       "      <td>0.003501</td>\n",
       "      <td>0.743300</td>\n",
       "      <td>0.003031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.501623</td>\n",
       "      <td>0.009172</td>\n",
       "      <td>0.672158</td>\n",
       "      <td>0.014683</td>\n",
       "      <td>0.939642</td>\n",
       "      <td>0.005941</td>\n",
       "      <td>0.754716</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.959495</td>\n",
       "      <td>0.003436</td>\n",
       "      <td>0.743228</td>\n",
       "      <td>0.003001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.529279</td>\n",
       "      <td>0.005894</td>\n",
       "      <td>0.703881</td>\n",
       "      <td>0.010031</td>\n",
       "      <td>0.936438</td>\n",
       "      <td>0.005922</td>\n",
       "      <td>0.754427</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.957956</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.741645</td>\n",
       "      <td>0.002881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.520847</td>\n",
       "      <td>0.004463</td>\n",
       "      <td>0.692708</td>\n",
       "      <td>0.012584</td>\n",
       "      <td>0.943696</td>\n",
       "      <td>0.005194</td>\n",
       "      <td>0.560165</td>\n",
       "      <td>0.005137</td>\n",
       "      <td>0.777674</td>\n",
       "      <td>0.003217</td>\n",
       "      <td>0.596587</td>\n",
       "      <td>0.007040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           method  fit_time_mean  fit_time_std  score_time_mean  \\\n",
       "0      No Scaling       0.411623      0.015341         0.714665   \n",
       "2    MaxAbsScaler       0.523627      0.008802         0.705701   \n",
       "1    MinMaxScaler       0.501623      0.009172         0.672158   \n",
       "3  StandardScaler       0.529279      0.005894         0.703881   \n",
       "4      Normalizer       0.520847      0.004463         0.692708   \n",
       "\n",
       "   score_time_std  accuracy_mean  accuracy_std  precision_mean  precision_std  \\\n",
       "0        0.011657       0.963281      0.001391        0.757487       0.000663   \n",
       "2        0.023381       0.939960      0.005883        0.754739       0.000698   \n",
       "1        0.014683       0.939642      0.005941        0.754716       0.000693   \n",
       "3        0.010031       0.936438      0.005922        0.754427       0.000622   \n",
       "4        0.012584       0.943696      0.005194        0.560165       0.005137   \n",
       "\n",
       "   recall_mean  recall_std   f1_mean    f1_std  \n",
       "0     0.970410    0.001742  0.758505  0.001312  \n",
       "2     0.959500    0.003501  0.743300  0.003031  \n",
       "1     0.959495    0.003436  0.743228  0.003001  \n",
       "3     0.957956    0.003258  0.741645  0.002881  \n",
       "4     0.777674    0.003217  0.596587  0.007040  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty dictionary to store results\n",
    "cv_results = {}\n",
    "\n",
    "# get scalers to compare\n",
    "scaler = {'No Scaling': 0,\n",
    "          'MinMaxScaler': MinMaxScaler(),\n",
    "          'MaxAbsScaler': MaxAbsScaler(),\n",
    "          'StandardScaler': StandardScaler(),\n",
    "          'Normalizer': Normalizer()}\n",
    "\n",
    "for method, s in scaler.items():\n",
    "    # reset X and y\n",
    "    X = df.drop(columns=['seo class'])\n",
    "    y = df['seo class']\n",
    "    \n",
    "    # applies scaler to X\n",
    "    if type(s) != int:\n",
    "        X = s.fit_transform(X)\n",
    "    \n",
    "    cv = cross_validate(clf, X, y, scoring=metrics, cv=sss)\n",
    "    cv_results[method] = cv\n",
    "    \n",
    "# format data for dataframe\n",
    "data = []\n",
    "for name, results in cv_results.items():\n",
    "    row = [name]\n",
    "    for k, v in results.items():\n",
    "        # add mean and standard deviation to data\n",
    "        row.append(v.mean())\n",
    "        row.append(v.std())\n",
    "    data.append(row)\n",
    "    \n",
    "# column names for dataframe\n",
    "columns = ['method']\n",
    "for k in cv.keys():\n",
    "    k = k.replace('test_', '')\n",
    "    columns.append(k+'_mean')\n",
    "    columns.append(k+'_std')\n",
    "\n",
    "# create data frame to display cv results\n",
    "results = pd.DataFrame(data, columns=columns)\n",
    "# save data frame as csv file\n",
    "results.to_csv('output/02-3_data_scaling.csv')\n",
    "results.sort_values(by=['f1_mean'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02-3.5_data_scaling_on_balanced_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>fit_time_mean</th>\n",
       "      <th>fit_time_std</th>\n",
       "      <th>score_time_mean</th>\n",
       "      <th>score_time_std</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.938330</td>\n",
       "      <td>0.020005</td>\n",
       "      <td>1.830700</td>\n",
       "      <td>0.031684</td>\n",
       "      <td>0.994816</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.994853</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.994685</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.994738</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.938448</td>\n",
       "      <td>0.013297</td>\n",
       "      <td>1.801425</td>\n",
       "      <td>0.033166</td>\n",
       "      <td>0.994521</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.994547</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.994392</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.994440</td>\n",
       "      <td>0.000097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.923413</td>\n",
       "      <td>0.013727</td>\n",
       "      <td>1.763639</td>\n",
       "      <td>0.012033</td>\n",
       "      <td>0.994521</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.994547</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.994392</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.994440</td>\n",
       "      <td>0.000097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Scaling</td>\n",
       "      <td>0.818617</td>\n",
       "      <td>0.042544</td>\n",
       "      <td>1.870577</td>\n",
       "      <td>0.050447</td>\n",
       "      <td>0.989987</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.989883</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.989842</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.989816</td>\n",
       "      <td>0.000198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.936391</td>\n",
       "      <td>0.011571</td>\n",
       "      <td>1.810310</td>\n",
       "      <td>0.005827</td>\n",
       "      <td>0.981208</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.981926</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.980779</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.980989</td>\n",
       "      <td>0.000264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           method  fit_time_mean  fit_time_std  score_time_mean  \\\n",
       "3  StandardScaler       0.938330      0.020005         1.830700   \n",
       "1    MinMaxScaler       0.938448      0.013297         1.801425   \n",
       "2    MaxAbsScaler       0.923413      0.013727         1.763639   \n",
       "0      No Scaling       0.818617      0.042544         1.870577   \n",
       "4      Normalizer       0.936391      0.011571         1.810310   \n",
       "\n",
       "   score_time_std  accuracy_mean  accuracy_std  precision_mean  precision_std  \\\n",
       "3        0.031684       0.994816      0.000087        0.994853       0.000089   \n",
       "1        0.033166       0.994521      0.000095        0.994547       0.000098   \n",
       "2        0.012033       0.994521      0.000095        0.994547       0.000098   \n",
       "0        0.050447       0.989987      0.000194        0.989883       0.000197   \n",
       "4        0.005827       0.981208      0.000264        0.981926       0.000255   \n",
       "\n",
       "   recall_mean  recall_std   f1_mean    f1_std  \n",
       "3     0.994685    0.000088  0.994738  0.000088  \n",
       "1     0.994392    0.000096  0.994440  0.000097  \n",
       "2     0.994392    0.000096  0.994440  0.000097  \n",
       "0     0.989842    0.000196  0.989816  0.000198  \n",
       "4     0.980779    0.000263  0.980989  0.000264  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty dictionary to store results\n",
    "cv_results = {}\n",
    "\n",
    "# get scalers to compare\n",
    "scaler = {'No Scaling': 0,\n",
    "          'MinMaxScaler': MinMaxScaler(),\n",
    "          'MaxAbsScaler': MaxAbsScaler(),\n",
    "          'StandardScaler': StandardScaler(),\n",
    "          'Normalizer': Normalizer()}\n",
    "# load data\n",
    "df = pd.read_csv('output/data_cleaned.csv')\n",
    "\n",
    "# 02-1: error encoding\n",
    "df1 = df[~df.lt(0).any(1)]\n",
    "X1 = df1.drop(columns=['seo class'])\n",
    "y1 = df1['seo class']\n",
    "\n",
    "# 02-2: class balancing\n",
    "sampler = SMOTETomek(random_state=2)\n",
    "X2, y2 = sampler.fit_resample(X1, y1)\n",
    "\n",
    "# create copy of sampled features\n",
    "df2 = X2.copy(deep=True)\n",
    "# add targets to copy\n",
    "df2['seo class'] = y2\n",
    "# save balanced data\n",
    "df2.to_csv('output/data_balanced.csv', index=False)\n",
    "\n",
    "for method, s in scaler.items():\n",
    "    # reset X and y\n",
    "    X3 = X2\n",
    "    y3 = y2\n",
    "    \n",
    "    # applies scaler to X\n",
    "    if type(s) != int:\n",
    "        X3 = s.fit_transform(X3)\n",
    "    \n",
    "    cv = cross_validate(clf, X3, y3, scoring=metrics, cv=sss)\n",
    "    cv_results[method] = cv\n",
    "    \n",
    "# format data for dataframe\n",
    "data = []\n",
    "for name, results in cv_results.items():\n",
    "    row = [name]\n",
    "    for k, v in results.items():\n",
    "        # add mean and standard deviation to data\n",
    "        row.append(v.mean())\n",
    "        row.append(v.std())\n",
    "    data.append(row)\n",
    "    \n",
    "# column names for dataframe\n",
    "columns = ['method']\n",
    "for k in cv.keys():\n",
    "    k = k.replace('test_', '')\n",
    "    columns.append(k+'_mean')\n",
    "    columns.append(k+'_std')\n",
    "\n",
    "# create data frame to display cv results\n",
    "results = pd.DataFrame(data, columns=columns)\n",
    "# save data frame as csv file\n",
    "results.to_csv('output/02-3.5_balanced_data_scaling.csv', index=False)\n",
    "results.sort_values(by=['f1_mean'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02-4_scaling_balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>fit_time_mean</th>\n",
       "      <th>fit_time_std</th>\n",
       "      <th>score_time_mean</th>\n",
       "      <th>score_time_std</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>error encoded</td>\n",
       "      <td>0.441485</td>\n",
       "      <td>0.057249</td>\n",
       "      <td>0.764770</td>\n",
       "      <td>0.082938</td>\n",
       "      <td>0.963281</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>0.757487</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.970410</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>0.758505</td>\n",
       "      <td>0.001312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>errors removed</td>\n",
       "      <td>0.361259</td>\n",
       "      <td>0.048442</td>\n",
       "      <td>0.589837</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.990434</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.780505</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.975232</td>\n",
       "      <td>0.006765</td>\n",
       "      <td>0.804394</td>\n",
       "      <td>0.000596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class balanced</td>\n",
       "      <td>0.845261</td>\n",
       "      <td>0.020758</td>\n",
       "      <td>2.126672</td>\n",
       "      <td>0.189929</td>\n",
       "      <td>0.989987</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.989883</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.989842</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.989816</td>\n",
       "      <td>0.000198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data scaled</td>\n",
       "      <td>0.958995</td>\n",
       "      <td>0.055208</td>\n",
       "      <td>1.812603</td>\n",
       "      <td>0.066597</td>\n",
       "      <td>0.994816</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.994853</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.994685</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.994738</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           method  fit_time_mean  fit_time_std  score_time_mean  \\\n",
       "0   error encoded       0.441485      0.057249         0.764770   \n",
       "1  errors removed       0.361259      0.048442         0.589837   \n",
       "2  class balanced       0.845261      0.020758         2.126672   \n",
       "3     data scaled       0.958995      0.055208         1.812603   \n",
       "\n",
       "   score_time_std  accuracy_mean  accuracy_std  precision_mean  precision_std  \\\n",
       "0        0.082938       0.963281      0.001391        0.757487       0.000663   \n",
       "1        0.001799       0.990434      0.000585        0.780505       0.000450   \n",
       "2        0.189929       0.989987      0.000194        0.989883       0.000197   \n",
       "3        0.066597       0.994816      0.000087        0.994853       0.000089   \n",
       "\n",
       "   recall_mean  recall_std   f1_mean    f1_std  \n",
       "0     0.970410    0.001742  0.758505  0.001312  \n",
       "1     0.975232    0.006765  0.804394  0.000596  \n",
       "2     0.989842    0.000196  0.989816  0.000198  \n",
       "3     0.994685    0.000088  0.994738  0.000088  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty dictionary to store results\n",
    "cv_results = {}\n",
    "\n",
    "# load original data\n",
    "df = pd.read_csv('output/data_cleaned.csv')\n",
    "X = df.drop(columns=['seo class'])\n",
    "y = df['seo class']\n",
    "\n",
    "# 02-1: remove errors\n",
    "df1 = df[~df.lt(0).any(1)]\n",
    "X1 = df1.drop(columns=['seo class'])\n",
    "y1 = df1['seo class']\n",
    "\n",
    "# 02-2: remove errors\n",
    "df2 = pd.read_csv('output/data_balanced.csv')\n",
    "X2 = df2.drop(columns=['seo class'])\n",
    "y2 = df2['seo class']\n",
    "\n",
    "# 02-3: data scaling\n",
    "# testing if scaling has a positive impact on balanced data\n",
    "scaler = StandardScaler()\n",
    "X3 = scaler.fit_transform(X2)\n",
    "y3 = y2\n",
    "\n",
    "# create copy of sampled and scaled features\n",
    "df3 = pd.DataFrame(X3, columns=X.columns)\n",
    "# add targets to copy\n",
    "df3['seo class'] = y3\n",
    "# save balanced and scaled data\n",
    "df3.to_csv('output/data_balanced_scaled.csv', index=False)\n",
    "\n",
    "# store data in dict\n",
    "data = {'error encoded': [X, y],\n",
    "        'errors removed': [X1, y1],\n",
    "        'class balanced': [X2, y2],\n",
    "        'data scaled': [X3, y3]}\n",
    "\n",
    "for method, d in data.items():\n",
    "    cv = cross_validate(clf, d[0], d[1], scoring=metrics, cv=sss)\n",
    "    cv_results[method] = cv\n",
    "\n",
    "# format data for dataframe\n",
    "data = []\n",
    "for name, results in cv_results.items():\n",
    "    row = [name]\n",
    "    for k, v in results.items():\n",
    "        # add mean and standard deviation to data\n",
    "        row.append(v.mean())\n",
    "        row.append(v.std())\n",
    "    data.append(row)\n",
    "    \n",
    "# column names for dataframe\n",
    "columns = ['method']\n",
    "for k in cv.keys():\n",
    "    k = k.replace('test_', '')\n",
    "    columns.append(k+'_mean')\n",
    "    columns.append(k+'_std')\n",
    "\n",
    "# create data frame to display cv results\n",
    "results = pd.DataFrame(data, columns=columns)\n",
    "# save data frame as csv file\n",
    "results.to_csv('output/02_data_optimization.csv')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
