{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02_data_optimization\n",
    "\n",
    "This notebook uses the Gaussian Naive Bayes Classifier to optimize the data set. These steps are preprocessing methods, that make the data more uniform and help boost the performance of the algorithms. As before, the results are cross validated by separating the data into 5 stratified shuffle splits and measuring the mean and standard deviation of the results.\n",
    "\n",
    "The most common techniques to handle missing data are compared. These are encoding the missing values with a placeholder (in this case -1), imputing the missing value by the mean of the feature or removing the sample in which a value for one feature is missing. Removing samples with missing data has the biggest positive impact on the data, increasing the accuracy from 96% to 99% and the f1 from 75% to 80%.\n",
    "\n",
    "The dataset is highly imbalanced, with a class distribution of roughly 48, 48, 1 and 1% per class. As such, methods to over or under sample these classes are tested. A combination of both SMOTE and Tomek, in which the higher classes are under sampled and the lower classes are over sampled, boosts f1 from 75% to 97% while the accuracy score also increases from 96% to 99%.\n",
    "\n",
    "Machine Learning algorithms generally perform better when the values are on an even scale. As such, different methods of scaling the data are compared. Since most of the features in the data set are either binary (0 or 1) or have very low variance (except for speed), the algorithm performs best when no scaler is applied.\n",
    "\n",
    "When testing the scaling methods on the balanced dataset, the StandardScaler increases the performance the most. The balanced and scaled model has an accuracy of 99% and f1 of 99%. The \"balanced\", and the \"balanced and scaled\" datasets are saved to <code>output/data_balanced.csv</code> and <code>output/data_balanced_scaled.csv</code> respectively. The latter is used in the next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Imports libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_validate, StratifiedShuffleSplit\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load and split data into features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('output/data_cleaned.csv')\n",
    "\n",
    "# split data into features and target\n",
    "X = df.drop(columns=['seo class'])\n",
    "y = df['seo class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Set evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of evaluation metrics\n",
    "metrics = {'accuracy': 'accuracy',\n",
    "           'precision': 'precision_macro', \n",
    "           'recall': 'recall_macro',\n",
    "           'f1': 'f1_macro'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Split data for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=.66, random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Set classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. Error encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>fit_time_mean</th>\n",
       "      <th>fit_time_std</th>\n",
       "      <th>score_time_mean</th>\n",
       "      <th>score_time_std</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>errors removed</td>\n",
       "      <td>0.325752</td>\n",
       "      <td>0.035651</td>\n",
       "      <td>0.568571</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.990434</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.780505</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.975232</td>\n",
       "      <td>0.006765</td>\n",
       "      <td>0.804394</td>\n",
       "      <td>0.000596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>errors encoded</td>\n",
       "      <td>0.396002</td>\n",
       "      <td>0.019392</td>\n",
       "      <td>0.730445</td>\n",
       "      <td>0.045020</td>\n",
       "      <td>0.963281</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>0.757487</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.970410</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>0.758505</td>\n",
       "      <td>0.001312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>errors imputed</td>\n",
       "      <td>0.519994</td>\n",
       "      <td>0.037170</td>\n",
       "      <td>0.705688</td>\n",
       "      <td>0.043502</td>\n",
       "      <td>0.886550</td>\n",
       "      <td>0.011275</td>\n",
       "      <td>0.749924</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.931416</td>\n",
       "      <td>0.005783</td>\n",
       "      <td>0.718006</td>\n",
       "      <td>0.004957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           method  fit_time_mean  fit_time_std  score_time_mean  \\\n",
       "1  errors removed       0.325752      0.035651         0.568571   \n",
       "0  errors encoded       0.396002      0.019392         0.730445   \n",
       "2  errors imputed       0.519994      0.037170         0.705688   \n",
       "\n",
       "   score_time_std  accuracy_mean  accuracy_std  precision_mean  precision_std  \\\n",
       "1        0.007692       0.990434      0.000585        0.780505       0.000450   \n",
       "0        0.045020       0.963281      0.001391        0.757487       0.000663   \n",
       "2        0.043502       0.886550      0.011275        0.749924       0.000614   \n",
       "\n",
       "   recall_mean  recall_std   f1_mean    f1_std  \n",
       "1     0.975232    0.006765  0.804394  0.000596  \n",
       "0     0.970410    0.001742  0.758505  0.001312  \n",
       "2     0.931416    0.005783  0.718006  0.004957  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty dictionary to store results\n",
    "cv_results = {}\n",
    "\n",
    "# create datasets to compare\n",
    "\n",
    "# errors removed\n",
    "df_clean = df[~df.lt(0).any(1)]\n",
    "X_clean = df_clean.drop(columns=['seo class'])\n",
    "y_clean = df_clean['seo class']\n",
    "\n",
    "# errors imputed\n",
    "df_impute = df.copy(deep=True)\n",
    "df_impute[df_impute < 0] = np.nan\n",
    "X_impute = df_impute.drop(columns=['seo class'])\n",
    "y_impute = df_impute['seo class']\n",
    "\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X_impute = imp_mean.fit_transform(X_impute, y_impute)\n",
    "\n",
    "# store data in dict\n",
    "data = {'errors encoded': [X, y],\n",
    "        'errors removed': [X_clean, y_clean],\n",
    "        'errors imputed': [X_impute, y_impute]}\n",
    "\n",
    "for method, d in data.items():\n",
    "    cv = cross_validate(clf, d[0], d[1], scoring=metrics, cv=sss)\n",
    "    cv_results[method] = cv\n",
    "    \n",
    "# format data for dataframe\n",
    "data = []\n",
    "for name, results in cv_results.items():\n",
    "    row = [name]\n",
    "    for k, v in results.items():\n",
    "        # add mean and standard deviation to data\n",
    "        row.append(v.mean())\n",
    "        row.append(v.std())\n",
    "    data.append(row)\n",
    "    \n",
    "# column names for dataframe\n",
    "columns = ['method']\n",
    "for k in cv.keys():\n",
    "    k = k.replace('test_', '')\n",
    "    columns.append(k+'_mean')\n",
    "    columns.append(k+'_std')\n",
    "    \n",
    "# create data frame to display cv results\n",
    "results = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# save data frame as csv file\n",
    "results.to_csv('output/5_error_encoding.csv')\n",
    "results.sort_values(by=['f1_mean'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2. Class Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>fit_time_mean</th>\n",
       "      <th>fit_time_std</th>\n",
       "      <th>score_time_mean</th>\n",
       "      <th>score_time_std</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>0.891233</td>\n",
       "      <td>0.008455</td>\n",
       "      <td>2.026337</td>\n",
       "      <td>0.010724</td>\n",
       "      <td>0.977984</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.978086</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.977641</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.977668</td>\n",
       "      <td>0.001215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>0.970513</td>\n",
       "      <td>0.016490</td>\n",
       "      <td>2.276229</td>\n",
       "      <td>0.149319</td>\n",
       "      <td>0.970725</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.971059</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.970725</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.000405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.006502</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.963804</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>0.963946</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>0.963819</td>\n",
       "      <td>0.002159</td>\n",
       "      <td>0.963506</td>\n",
       "      <td>0.002213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Sampling</td>\n",
       "      <td>0.436416</td>\n",
       "      <td>0.058127</td>\n",
       "      <td>0.745758</td>\n",
       "      <td>0.057335</td>\n",
       "      <td>0.963281</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>0.757487</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.970410</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>0.758505</td>\n",
       "      <td>0.001312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               method  fit_time_mean  fit_time_std  score_time_mean  \\\n",
       "3          SMOTETomek       0.891233      0.008455         2.026337   \n",
       "1   RandomOverSampler       0.970513      0.016490         2.276229   \n",
       "2  RandomUnderSampler       0.003409      0.000240         0.006502   \n",
       "0         No Sampling       0.436416      0.058127         0.745758   \n",
       "\n",
       "   score_time_std  accuracy_mean  accuracy_std  precision_mean  precision_std  \\\n",
       "3        0.010724       0.977984      0.001153        0.978086       0.001137   \n",
       "1        0.149319       0.970725      0.000390        0.971059       0.000392   \n",
       "2        0.000255       0.963804      0.002169        0.963946       0.002221   \n",
       "0        0.057335       0.963281      0.001391        0.757487       0.000663   \n",
       "\n",
       "   recall_mean  recall_std   f1_mean    f1_std  \n",
       "3     0.977641    0.001193  0.977668  0.001215  \n",
       "1     0.970725    0.000390  0.970588  0.000405  \n",
       "2     0.963819    0.002159  0.963506  0.002213  \n",
       "0     0.970410    0.001742  0.758505  0.001312  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty dictionary to store results\n",
    "cv_results = {}\n",
    "\n",
    "# get scalers to compare\n",
    "sampler = {'No Sampling': 0,\n",
    "           'RandomOverSampler': RandomOverSampler(random_state=2),\n",
    "           'RandomUnderSampler': RandomUnderSampler(random_state=2),\n",
    "           'SMOTETomek': SMOTETomek(random_state=2)}\n",
    "\n",
    "for method, s in sampler.items():\n",
    "    # reset X and y\n",
    "    X = df.drop(columns=['seo class'])\n",
    "    y = df['seo class']\n",
    "    \n",
    "    # applies sampler to X and y\n",
    "    if type(s) != int:\n",
    "        X, y = s.fit_resample(X, y)\n",
    "    \n",
    "    cv = cross_validate(clf, X, y, scoring=metrics, cv=sss)\n",
    "    cv_results[method] = cv\n",
    "    \n",
    "# format data for dataframe\n",
    "data = []\n",
    "for name, results in cv_results.items():\n",
    "    row = [name]\n",
    "    for k, v in results.items():\n",
    "        # add mean and standard deviation to data\n",
    "        row.append(v.mean())\n",
    "        row.append(v.std())\n",
    "    data.append(row)\n",
    "    \n",
    "# column names for dataframe\n",
    "columns = ['method']\n",
    "for k in cv.keys():\n",
    "    k = k.replace('test_', '')\n",
    "    columns.append(k+'_mean')\n",
    "    columns.append(k+'_std')\n",
    "    \n",
    "# create data frame to display cv results\n",
    "results = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# save data frame as csv file\n",
    "results.to_csv('output/5_class_balancing.csv')\n",
    "results.sort_values(by=['f1_mean'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3. Data Scaling with inbalanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>fit_time_mean</th>\n",
       "      <th>fit_time_std</th>\n",
       "      <th>score_time_mean</th>\n",
       "      <th>score_time_std</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Scaling</td>\n",
       "      <td>0.404903</td>\n",
       "      <td>0.018503</td>\n",
       "      <td>0.673342</td>\n",
       "      <td>0.017692</td>\n",
       "      <td>0.963281</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>0.757487</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.970410</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>0.758505</td>\n",
       "      <td>0.001312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.526127</td>\n",
       "      <td>0.011090</td>\n",
       "      <td>0.696275</td>\n",
       "      <td>0.016563</td>\n",
       "      <td>0.939960</td>\n",
       "      <td>0.005883</td>\n",
       "      <td>0.754739</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.959500</td>\n",
       "      <td>0.003501</td>\n",
       "      <td>0.743300</td>\n",
       "      <td>0.003031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.513910</td>\n",
       "      <td>0.013580</td>\n",
       "      <td>0.674625</td>\n",
       "      <td>0.027230</td>\n",
       "      <td>0.939642</td>\n",
       "      <td>0.005941</td>\n",
       "      <td>0.754716</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.959495</td>\n",
       "      <td>0.003436</td>\n",
       "      <td>0.743228</td>\n",
       "      <td>0.003001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.506076</td>\n",
       "      <td>0.014552</td>\n",
       "      <td>0.658166</td>\n",
       "      <td>0.023820</td>\n",
       "      <td>0.936438</td>\n",
       "      <td>0.005922</td>\n",
       "      <td>0.754427</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.957956</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.741645</td>\n",
       "      <td>0.002881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.487678</td>\n",
       "      <td>0.006445</td>\n",
       "      <td>0.630861</td>\n",
       "      <td>0.005555</td>\n",
       "      <td>0.943696</td>\n",
       "      <td>0.005194</td>\n",
       "      <td>0.560165</td>\n",
       "      <td>0.005137</td>\n",
       "      <td>0.777674</td>\n",
       "      <td>0.003217</td>\n",
       "      <td>0.596587</td>\n",
       "      <td>0.007040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           method  fit_time_mean  fit_time_std  score_time_mean  \\\n",
       "0      No Scaling       0.404903      0.018503         0.673342   \n",
       "2    MaxAbsScaler       0.526127      0.011090         0.696275   \n",
       "1    MinMaxScaler       0.513910      0.013580         0.674625   \n",
       "3  StandardScaler       0.506076      0.014552         0.658166   \n",
       "4      Normalizer       0.487678      0.006445         0.630861   \n",
       "\n",
       "   score_time_std  accuracy_mean  accuracy_std  precision_mean  precision_std  \\\n",
       "0        0.017692       0.963281      0.001391        0.757487       0.000663   \n",
       "2        0.016563       0.939960      0.005883        0.754739       0.000698   \n",
       "1        0.027230       0.939642      0.005941        0.754716       0.000693   \n",
       "3        0.023820       0.936438      0.005922        0.754427       0.000622   \n",
       "4        0.005555       0.943696      0.005194        0.560165       0.005137   \n",
       "\n",
       "   recall_mean  recall_std   f1_mean    f1_std  \n",
       "0     0.970410    0.001742  0.758505  0.001312  \n",
       "2     0.959500    0.003501  0.743300  0.003031  \n",
       "1     0.959495    0.003436  0.743228  0.003001  \n",
       "3     0.957956    0.003258  0.741645  0.002881  \n",
       "4     0.777674    0.003217  0.596587  0.007040  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty dictionary to store results\n",
    "cv_results = {}\n",
    "\n",
    "# get scalers to compare\n",
    "scaler = {'No Scaling': 0,\n",
    "          'MinMaxScaler': MinMaxScaler(),\n",
    "          'MaxAbsScaler': MaxAbsScaler(),\n",
    "          'StandardScaler': StandardScaler(),\n",
    "          'Normalizer': Normalizer()}\n",
    "\n",
    "for method, s in scaler.items():\n",
    "    # reset X and y\n",
    "    X = df.drop(columns=['seo class'])\n",
    "    y = df['seo class']\n",
    "    \n",
    "    # applies scaler to X\n",
    "    if type(s) != int:\n",
    "        X = s.fit_transform(X)\n",
    "    \n",
    "    cv = cross_validate(clf, X, y, scoring=metrics, cv=sss)\n",
    "    cv_results[method] = cv\n",
    "    \n",
    "# format data for dataframe\n",
    "data = []\n",
    "for name, results in cv_results.items():\n",
    "    row = [name]\n",
    "    for k, v in results.items():\n",
    "        # add mean and standard deviation to data\n",
    "        row.append(v.mean())\n",
    "        row.append(v.std())\n",
    "    data.append(row)\n",
    "    \n",
    "# column names for dataframe\n",
    "columns = ['method']\n",
    "for k in cv.keys():\n",
    "    k = k.replace('test_', '')\n",
    "    columns.append(k+'_mean')\n",
    "    columns.append(k+'_std')\n",
    "    \n",
    "# create data frame to display cv results\n",
    "results = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# save data frame as csv file\n",
    "results.to_csv('output/5_data_scaling.csv')\n",
    "results.sort_values(by=['f1_mean'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Combining best performing preprocessing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load original data\n",
    "df = pd.read_csv('output/data_cleaned.csv')\n",
    "X = df.drop(columns=['seo class'])\n",
    "y = df['seo class']\n",
    "\n",
    "# removes errors\n",
    "df = df[~df.lt(0).any(1)]\n",
    "X = df.drop(columns=['seo class'])\n",
    "y = df['seo class']\n",
    "\n",
    "# applies SMOTETomek to balance classes\n",
    "s = SMOTETomek(random_state=2)\n",
    "X, y = s.fit_resample(X, y)\n",
    "\n",
    "# save balanced cleaned data\n",
    "# create copy of sampled features\n",
    "df_balanced = X.copy(deep=True)\n",
    "# add targets to copy\n",
    "df_balanced['seo class'] = y\n",
    "# save balanced data\n",
    "df_balanced.to_csv('output/data_cleaned_balanced.csv', index=False)\n",
    "\n",
    "# no data scaling because it was the best performing method\n",
    "## possible: re-test after other two preprocessing steps\n",
    "## incase it improves the data further\n",
    "\n",
    "cv = cross_validate(clf, X, y, scoring=metrics, cv=sss)\n",
    "\n",
    "# format data for dataframe\n",
    "data = []\n",
    "row = []\n",
    "for k, v in cv.items():\n",
    "    # add mean and standard deviation to data\n",
    "    row.append(v.mean())\n",
    "    row.append(v.std())\n",
    "data.append(row)\n",
    "    \n",
    "# column names for dataframe\n",
    "columns = []\n",
    "for k in cv.keys():\n",
    "    k = k.replace('test_', '')\n",
    "    columns.append(k+'_mean')\n",
    "    columns.append(k+'_std')\n",
    "    \n",
    "# create data frame to display cv results\n",
    "results = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# save data frame as csv file\n",
    "results.to_csv('output/5_data_optimization.csv')\n",
    "results.T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
